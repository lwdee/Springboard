{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative filtering using SVD and matrix factorization\n",
    "\n",
    "The scikit-surprise library is designed specifically for building and evaluating recommendation engines. More information can be found at http://surpriselib.com/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import NMF, SVD, KNNWithMeans\n",
    "from surprise import dump\n",
    "from surprise.model_selection import train_test_split, cross_validate, GridSearchCV, KFold\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books = pd.read_pickle('datasets/clean/books_clean.pkl')\n",
    "df_ratings = pd.read_csv( 'datasets/raw/ratings_raw.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test-Validation Split\n",
    "\n",
    "We'll use 80% of the data for training, 10% for testing, and set aside the last 10% for validation to be used when we build the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4081</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating\n",
       "0        1      258       5\n",
       "1        2     4081       4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of users in total: 53424\n",
      "# of users in the training set:  53424\n",
      "# of books in total: 10000\n",
      "# of books in the training set:  10000\n",
      "% of books in the training, testing and validation set:  0.7999999665354802 0.3000000501967797 0.3000000501967797\n"
     ]
    }
   ],
   "source": [
    "# train-test split by randomly split on 'df_ratings' dataset (on user-book rating combination)\n",
    "idx = list(df_ratings.index)\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(idx) # shuffle the list of index\n",
    "\n",
    "# 80% trainset, 10% testset, 10% validation (valset)\n",
    "lower_threshold = int(0.8 * len(df_ratings)) \n",
    "upper_threshold = int(0.9 * len(df_ratings)) \n",
    "trainset = df_ratings.loc[idx[:lower_threshold]]                             \n",
    "testset = df_ratings.loc[idx[lower_threshold:upper_threshold]]\n",
    "valset = df_ratings.loc[idx[upper_threshold:]]\n",
    "\n",
    "print(\"# of users in total:\" , df_ratings.user_id.nunique())\n",
    "print(\"# of users in the training set: \", trainset.user_id.nunique())\n",
    "print(\"# of books in total:\" , df_ratings.book_id.nunique())\n",
    "print(\"# of books in the training set: \", trainset.book_id.nunique())\n",
    "print(\"% of books in the training, testing and validation set: \",\n",
    "      len(trainset)/len(df_ratings), len(testset)/len(df_ratings), \n",
    "      len(valset)/len(df_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix factorization using scikit-surprise package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trainset and testset into Surprise\n",
    "\n",
    "# create a Reader object with the rating_scale from 1 to 5\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# load trainset, note: \n",
    "#    the columns must correspond to user id, item id and ratings in the exact order\n",
    "data_train = Dataset.load_from_df(trainset, reader)\n",
    "# prepare a trainset object out of the training data to feed to .fit() method\n",
    "training = data_train.build_full_trainset()\n",
    "\n",
    "\n",
    "# load testset\n",
    "data_test = Dataset.load_from_df(testset, reader)\n",
    "# prepare a testset object out of the test data to feed to .test() method\n",
    "testing = data_test.construct_testset(data_test.raw_ratings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD without bias for matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8252\n",
      "(53424, 20) (10000, 20)\n",
      "CPU times: user 4min 18s, sys: 2.13 s, total: 4min 20s\n",
      "Wall time: 4min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# simple SVD model\n",
    "svd = SVD(n_factors=20, n_epochs = 30, biased=False) # initiate a SVD algorithm object\n",
    "svd.fit(training) # training on the trainset\n",
    "pred_svd = svd.test(testing) # predict ratings for the testset\n",
    "accuracy.rmse(pred_svd) # compute RMSE score\n",
    "\n",
    "# user and item matrix with latent features\n",
    "mean = svd.trainset.global_mean # global mean rating of the trainset\n",
    "user_latent, item_latent = svd.pu, svd.qi\n",
    "print(user_latent.shape, item_latent.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD with bias for matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8291\n",
      "(53424, 20) (10000, 20)\n",
      "CPU times: user 4min 22s, sys: 7.84 s, total: 4min 30s\n",
      "Wall time: 4min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# SVD model with bias\n",
    "svd = SVD(n_factors=20, n_epochs = 30, biased=True) # initiate a SVD algorithm object\n",
    "svd.fit(training) # training on the trainset\n",
    "pred_svd = svd.test(testing) # predict ratings for the testset\n",
    "accuracy.rmse(pred_svd) # compute RMSE score\n",
    "\n",
    "# user and item matrix with latent features\n",
    "mean = svd.trainset.global_mean # global mean rating of the trainset\n",
    "user_latent, item_latent = svd.pu, svd.qi\n",
    "print(user_latent.shape, item_latent.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF (non-negative matrix factorization) without bias term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9179\n",
      "(53424, 20) (10000, 20)\n",
      "CPU times: user 5min 9s, sys: 9.72 s, total: 5min 18s\n",
      "Wall time: 5min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# simple NMF model\n",
    "nmf = NMF(n_factors=20, n_epochs = 30, biased=False) # initiate a NMF algorithm object\n",
    "nmf.fit(training) # training on the trainset\n",
    "pred_nmf = nmf.test(testing) # predict ratings for the testset\n",
    "accuracy.rmse(pred_nmf) # compute RMSE score\n",
    "\n",
    "# user and item matrix with latent features\n",
    "mean = nmf.trainset.global_mean # global mean rating of the trainset\n",
    "user_latent, item_latent = nmf.pu, nmf.qi\n",
    "print(user_latent.shape, item_latent.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# simple NMF model\n",
    "knn = KNNWithMean(k=40, min_k=1) # initiate a KNN algorithm object\n",
    "knn.fit(training) # training on the trainset\n",
    "pred_knn = knn.test(testing) # predict ratings for the testset\n",
    "accuracy.rmse(pred_knn) # compute RMSE score\n",
    "\n",
    "# user and item matrix with latent features\n",
    "mean = knn.trainset.global_mean # global mean rating of the trainset\n",
    "user_latent, item_latent = knn.pu, knn.qi\n",
    "print(user_latent.shape, item_latent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
